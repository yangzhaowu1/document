# 并发编程
## context
context翻译成中文是”上下文”，即它可以控制一组呈树状结构的goroutine，每个goroutine拥有相同的上下文
context.Context Go 语言中用来设置截止日期、同步信号，传递请求相关值的结构体
在 Goroutine 构成的树形结构中对信号进行同步以减少计算资源的浪费是 context.Context 的最大作用
### 接口定义
```go
//src/context/context.go
type Context interface {
	Deadline() (deadline time.Time, ok bool)
	Done() <-chan struct{}
	Err() error
	Value(key interface{}) interface{}
}
```
#### Deadline()
deadline：context.Context 被取消的时间，也就是完成工作的截止日期
ok：标识是否已设置deadline；如果没有设置deadline，则ok == false，此时deadline为一个初始值的time.Time值
#### Done()
Done — 返回一个 Channel，这个 Channel 会在当前工作完成或者上下文被取消后关闭，多次调用 Done 方法会返回同一个 Channel；

#### Err()
该方法描述context关闭的原因

* 因deadline关闭：“context deadline exceeded”；
* 因主动关闭： “context canceled”。
* 
当context关闭后，Err()返回context的关闭原因；
当context还未关闭时，Err()返回nil

#### Value()
用于在树状分布的goroutine间传递信息
对于同一个上下文来说，多次调用 Value 并传入相同的 Key 会返回相同的结果，该方法可以用来传递请求特定的数据；

### 空context
context包中定义了一个空的context， 名为emptyCtx，用于context的根节点，空的context只是简单的实现了Context，本身不包含任何值，仅用于其他context的父节点
#### Background
context包中定义了一个公用的emptCtx全局变量，名为background
```go
var background = new(emptyCtx)
func Background() Context {
    return background
}
```
上下文的默认值，所有其他的上下文都应该从它衍生出来
#### TODO
仅在不确定应该使用哪种上下文时使用
与Background互为别名，没有太大的差别，只是在使用和语义上稍有不同
### 创建
#### cancelCtx
```go
//src/context/context.go
type cancelCtx struct {
    Context

    mu       sync.Mutex            // protects following fields
    done     chan struct{}         // created lazily, closed by first cancel call
    children map[canceler]struct{} // set to nil by the first cancel call
    err      error                 // set to non-nil by the first cancel call
}
```
children中记录了由此context派生的所有child，此context被cancel时会把其中的所有child都cancel掉。

cancelCtx与deadline和value无关，所以只需要实现Done()和Err()外露接口即可。

### 总结
* Context仅仅是一个接口定义，根据实现的不同，可以衍生出不同的context类型；
* cancelCtx实现了Context接口，通过WithCancel()创建cancelCtx实例；
* timerCtx实现了Context接口，通过WithDeadline()和WithTimeout()创建timerCtx实例；
* valueCtx实现了Context接口，通过WithValue()创建valueCtx实例；
* 三种context实例可互为父节点，从而可以组合成不同的应用形式；

## sync
Go 语言在 sync 包中提供了用于同步的一些基本原语，包括常见的 sync.Mutex、sync.RWMutex、sync.WaitGroup、sync.Once 和 sync.Cond
### Mutex
Go 语言的 sync.Mutex 由两个字段 state 和 sema 组成
```go
//src/sync/mutex.go
type Mutex struct {
    //当前互斥锁的状态
	state int32
	//控制锁状态的信号量;协程阻塞等待该信号量，解锁的协程释放信号量从而唤醒等待信号量的协程
	sema  uint32
}
```
#### state
互斥锁的状态比较复杂，如下图所示，最低三位分别表示 Locked、Woken 、Starving，剩下的位置用来表示当前有多少个 Goroutine 在等待互斥锁的释放
![Mutex state](vx_images/540785920220663.png)
在默认情况下，互斥锁的所有状态位都是 0，int32 中的不同位分别表示了不同的状态

* Locked — 表示互斥锁的锁定状态；0：没有锁定 1：已被锁定
* Woken — 表示是否有协程已被唤醒，0：没有协程唤醒 1：已有协程唤醒，正在加锁过程中
* Starving — 表示该Mutex是否处于饥饿状态，0：没有饥饿 1：饥饿状态，说明有协程阻塞了超过1ms
* waitersCount — 表示阻塞等待锁的协程个数，协程解锁时根据此值来判断是否需要释放信号量

协程之间抢锁实际上是抢给Locked赋值的权利，能给Locked域置1，就说明抢锁成功。抢不到的话就阻塞等待Mutex.sema信号量，一旦持有锁的协程解锁，等待的协程会依次被唤醒

#### 正常模式和饥饿模式
* 正常模式：锁的等待者会按照先进先出的顺序获取锁。但是刚被唤起的 Goroutine 与新创建的 Goroutine （自旋）竞争时，大概率会获取不到锁，为了减少这种情况的出现，一旦 Goroutine 超过 1ms 没有获取到锁，它就会将当前互斥锁切换饥饿模式（不允许自旋），防止部分 Goroutine 被『饿死』
* 饥饿模式：目的是保证互斥锁的公平性；互斥锁会直接交给等待队列最前面的 Goroutine。新的 Goroutine 在该状态下不能获取锁、也不会进入自旋状态，它们只会在队列的末尾等待。如果一个 Goroutine 获得了互斥锁并且它在队列的末尾或者它等待的时间少于 1ms，那么当前的互斥锁就会切换回正常模式

性能对比
* 正常模式下的互斥锁能够提供更好地性能
* 饥饿模式的能避免 Goroutine 由于陷入等待无法获取锁而造成的高尾延时

#### 加锁和解锁
##### 加锁
1. 判断当前 Goroutine 能否进入自旋；
2. 通过自旋等待互斥锁的释放；
3. 计算互斥锁的最新状态；
4. 更新（使用 CAS 函数）互斥锁的状态并获取锁；

##### 解锁
在正常模式下，上述代码会使用如下所示的处理过程：
* 如果互斥锁不存在等待者或者互斥锁的 mutexLocked、mutexStarving、mutexWoken 状态不都为 0，那么当前方法可以直接返回，不需要唤醒其他等待者；
* 如果互斥锁存在等待者，会通过 sync.runtime_Semrelease 唤醒等待者并移交锁的所有权；
在饥饿模式下：直接调用 sync.runtime_Semrelease 将当前锁交给下一个正在尝试获取锁的等待者，等待者被唤醒后会得到锁，在这时互斥锁还不会退出饥饿状态；

为什么重复解锁会panic: 如果多次Unlock()，那么可能每次都释放一个信号量，这样会唤醒多个协程，多个协程唤醒后会继续在Lock()的逻辑里抢锁，势必会增加Lock()实现的复杂度，也会引起不必要的协程切换
##### 小结
互斥锁的加锁过程比较复杂，它涉及自旋、信号量以及调度等概念：

* 如果互斥锁处于初始化状态，会通过置位 mutexLocked 加锁；
* 如果互斥锁处于 mutexLocked 状态并且在普通模式下工作，会进入自旋，执行 30 次 PAUSE 指令消耗 CPU 时间等待锁的释放；
* 如果当前 Goroutine 等待锁的时间超过了 1ms，互斥锁就会切换到饥饿模式；
* 互斥锁在正常情况下会通过 runtime.sync_runtime_SemacquireMutex 将尝试获取锁的 Goroutine 切换至休眠状态，等待锁的持有者唤醒；
* 如果当前 Goroutine 是互斥锁上的最后一个等待的协程或者等待的时间小于 1ms，那么它会将互斥锁切换回正常模式；

互斥锁的解锁过程与之相比就比较简单，其代码行数不多、逻辑清晰
* 当互斥锁已经被解锁时，调用 sync.Mutex.Unlock 会直接抛出异常；
当互斥锁处于饥饿模式时，将锁的所有权交给队列中的下一个等待者，等待者会负责设置 mutexLocked 标志位；
当互斥锁处于普通模式时，如果没有 Goroutine 等待锁的释放或者已经有被唤醒的 Goroutine 获得了锁，会直接返回；在其他情况下会通过 sync.runtime_Semrelease 唤醒对应的 Goroutine
#### 自旋
加锁时，如果当前Locked位为1，说明该锁当前由其他协程持有，尝试加锁的协程并不是马上转入阻塞，而是会持续的探测Locked位是否变为0，这个过程即为自旋过程。

* 自旋时间很短，但如果在自旋过程中发现锁已被释放，那么协程可以立即获取锁。此时即便有协程被唤醒也无法获取锁，只能再次阻塞。
* 自旋的好处是，当加锁失败时不必立即转入阻塞，有一定机会获取到锁，这样可以避免协程的切换

自旋对应于CPU的”PAUSE”指令，CPU对该指令什么都不做，相当于CPU空转，对程序而言相当于sleep了一小段时间，时间非常短，当前实现是30个时钟周期。自旋过程中会持续探测Locked是否变为0，连续两次探测间隔就是执行这些PAUSE指令，它不同于sleep，不需要将协程转为睡眠状态

自旋是一种多线程同步机制，当前的进程在进入自旋的过程中会一直保持 CPU 的占用，持续检查某个条件是否为真。在多核的 CPU 上，自旋可以避免 Goroutine 的切换，使用恰当会对性能带来很大的增益，但是使用的不恰当就会拖慢整个程序，所以 Goroutine 进入自旋的条件非常苛刻
* 互斥锁只有在普通模式才能进入自旋；
* runtime.sync_runtime_canSpin 需要返回 true：
* 运行在多 CPU 的机器上；
* 自旋次数要足够小，通常为4，即自旋最多4次
* 协程调度机制中的Process数量要大于1，比如使用GOMAXPROCS()将处理器设置为1就不能启用自旋
* 协程调度机制中的可运行队列必须为空，否则会延迟协程调度

自旋的优势是更充分的利用CPU，尽量避免协程切换。因为当前申请加锁的协程拥有CPU，如果经过短时间的自旋可以获得锁，当前协程可以继续运行，不必进入阻塞状态。

如果自旋过程中获得锁，那么之前被阻塞的协程将无法获得锁，如果加锁的协程特别多，每次都通过自旋获得锁，那么之前被阻塞的进程将很难获得锁，从而进入饥饿状态。

为了避免协程长时间无法获取锁，自1.8版本以来增加了一个状态，即Mutex的Starving状态。这个状态下不会自旋，一旦有协程释放锁，那么一定会唤醒一个协程并成功加锁。

### RWMutex 
读写互斥锁 sync.RWMutex 是细粒度的互斥锁，它不限制资源的并发读，但是读写、写写操作无法并行执行
```go
//src/sync/rwmutex.go
type RWMutex struct {
    //复用互斥锁提供的能力
	w           Mutex
	
	//写阻塞等待的信号量，最后一个读者释放锁时会释放信号量
	writerSem   uint32
	
	//读阻塞的协程等待的信号量，持有写锁的协程释放锁后会释放信号量
	readerSem   uint32
	
	//当前正在执行的读操作数量
	readerCount int32
	//当写操作被阻塞时等待的读操作个数
	readerWait  int32
}
```
#### 写锁
加锁：

1. 阻塞后续的写操作；，其他 Goroutine 在获取写锁时会进入自旋或者休眠；
2. 阻塞后续的读操作
3. 有正在进行读的操作时，进入休眠状态等待所有读锁所有者执行结束后释放 writerSem 信号量将当前协程唤醒

如何阻塞读操作：将readerCount减去2^30，使其变成了负值

1. 新的读操作检测到readerCount为负值，便知道有写操作在进行，只好阻塞等待。
2. 已有的读操作个数并不会丢失，只需要将readerCount加上2^30即可获得；

解锁：

 1. 释放读锁；
 2. 通过 for 循环释放所有因为获取读锁而陷入等待的 Goroutine：
 3.  释放写锁；

获取写锁时会先阻塞写锁的获取，后阻塞读锁的获取，这种策略能够保证读操作不会被连续的写操作[饿死]

#### 读锁
加锁： 

1. 增加读操作计数，readerCount 加一
1. 如果该方法返回负数 — 其他 Goroutine 获得了写锁，当前 Goroutine 就会陷入休眠等待锁的释放；
2. 如果该方法的结果为非负数 ： 没有 Goroutine 获得写锁，当前方法会成功返回

释放：

1. 减少readerCount计数
2. 如果返回值大于等于零 ： 读锁直接解锁成功；
3. 如果返回值小于零 ： 有一个正在执行的写操作，减少获取锁的写操作等待的读操作数 readerWait 并在所有读操作都被释放之后触发写操作的信号量 writerSem，该信号量被触发时，调度器就会唤醒尝试获取写锁的 Goroutine

#### 总结
1. 调用 sync.RWMutex.Lock 尝试获取写锁时；
    * 每次 sync.RWMutex.RUnlock 都会将 readerCount 其减一，当它归零时该 Goroutine 会获得写锁；
    * 将 readerCount 减少 rwmutexMaxReaders 个数以阻塞后续的读操作；
2. 调用 sync.RWMutex.Unlock 释放写锁时，会先通知所有的读操作，然后才会释放持有的互斥锁；

读写互斥锁在互斥锁之上提供了额外的更细粒度的控制，能够在读操作远远多于写操作时提升性能

### WaitGroup 
sync.WaitGroup 可以等待一组 Goroutine 的返回
```go
//src/sync/waitgroup.go
type WaitGroup struct {
    //保证 sync.WaitGroup 不会被开发者通过再赋值的方式拷贝
	noCopy noCopy
	//存储着状态和信号量
	state1 [3]uint32
}
```
state1是个长度为3的数组，其中包含了state和一个信号量，而state实际上是两个计数器：

* counter： 当前还未执行结束的goroutine计数器
* waiter count: 等待goroutine-group结束的goroutine数量，即有多少个等候者
* semaphore: 信号量

#### Add(delta int)
```go
//伪代码
func (wg *WaitGroup) Add(delta int) {
    statep, semap := wg.state() //获取state和semaphore地址指针

    state := atomic.AddUint64(statep, uint64(delta)<<32) //把delta左移32位累加到state，即累加到counter中
    v := int32(state >> 32) //获取counter值
    w := uint32(state)      //获取waiter值

    if v < 0 {              //经过累加后counter值变为负值，panic
        panic("sync: negative WaitGroup counter")
    }

    //经过累加后，此时，counter >= 0
    //如果counter为正，说明不需要释放信号量，直接退出
    //如果waiter为零，说明没有等待者，也不需要释放信号量，直接退出
    if v > 0 || w == 0 {
        return
    }

    //此时，counter一定等于0，而waiter一定大于0（内部维护waiter，不会出现小于0的情况），
    //先把counter置为0，再释放waiter个数的信号量
    *statep = 0
    for ; w != 0; w-- {
        runtime_Semrelease(semap, false) //释放信号量，执行一次释放一个，唤醒一个等待者
    }
}
```
1. 一是把delta值累加到counter中，因为delta可以为负值，也就是说counter有可能变成0或负值
2. 当counter值变为0时，根据waiter数值释放等量的信号量，把等待的goroutine全部唤醒，如果counter变为负值，则panic

#### Wait()
```go
//伪代码
func (wg *WaitGroup) Wait() {
    statep, semap := wg.state() //获取state和semaphore地址指针
    for {
        state := atomic.LoadUint64(statep) //获取state值
        v := int32(state >> 32)            //获取counter值
        w := uint32(state)                 //获取waiter值
        if v == 0 {                        //如果counter值为0，说明所有goroutine都退出了，不需要待待，直接返回
            return
        }

        // 使用CAS（比较交换算法）累加waiter，累加可能会失败，失败后通过for loop下次重试
        if atomic.CompareAndSwapUint64(statep, state, state+1) {
            runtime_Semacquire(semap) //累加成功后，等待信号量唤醒自己
            return
        }
    }
}
```
1. 累加waiter, 
2. 阻塞等待信号量
CAS算法保证有多个goroutine同时执行Wait()时也能正确累加waiter
#### Done()
把counter减1，我们知道Add()可以接受负值，所以Done实际上只是调用了Add(-1

#### 小结
* sync.WaitGroup 必须在 sync.WaitGroup.Wait 方法返回之后才能被重新使用；
* sync.WaitGroup.Done 只是对 sync.WaitGroup.Add 方法的简单封装，我们可以向 sync.WaitGroup.Add 方法传入任意负数（需要保证计数器非负）快速将计数器归零以唤醒等待的 Goroutine；
* 可以同时有多个 Goroutine 等待当前 sync.WaitGroup 计数器的归零，这些 Goroutine 会被同时唤醒
* 

### Once
Go 语言标准库中 sync.Once 可以保证在 Go 程序运行期间的某段代码只会执行一次
```
type Once struct {
    //用于标识代码块是否执行过
	done uint32
	//互斥锁 sync.Mutex
	m    Mutex
}
```
sync.Once.Do 是 sync.Once 结构体对外唯一暴露的方法，该方法会接收一个入参为空的函数：

* 如果传入的函数已经执行过，会直接返回；
* 如果传入的函数没有执行过，会调用 sync.Once.doSlow 执行传入的函数

### Cond
Go 语言标准库中还包含条件变量 sync.Cond，它可以让一组的 Goroutine 都在满足特定条件时被唤醒。每一个 sync.Cond 结构体在初始化时都需要传入一个互斥锁
```
type Cond struct {
    //保证结构体不会在编译期间拷贝
	noCopy  noCopy
	//保护内部的 notify 字段
	L       Locker
	// 一个 Goroutine 的链表，它是实现同步机制的核心结构
	notify  notifyList
	//禁止运行期间发生的拷贝
	checker copyChecker
}

type notifyList struct {
    //当前正在等待的Goroutine 的索引
	wait uint32
	//当前已经通知到的 Goroutine 的索引
	notify uint32

	lock mutex
	//指向的链表的头
	head *sudog
	//指向的链表的尾
	tail *sudog
}
```
sync.Cond.Wait 方法会将当前 Goroutine 陷入休眠状态
* 调用 runtime.notifyListAdd 将等待计数器加一并解锁；
* 调用 runtime.notifyListWait 等待其他 Goroutine 的唤醒并加锁

sync.Cond.Signal 和 sync.Cond.Broadcast 就是用来唤醒陷入休眠的 Goroutine 的方法
* sync.Cond.Signal 方法会唤醒队列最前面的 Goroutine；
* sync.Cond.Broadcast 方法会唤醒队列中全部的 Goroutine

sync.Cond 不是一个常用的同步机制，但是在条件长时间无法满足时，与使用 for {} 进行忙碌等待相比，sync.Cond 能够让出处理器的使用权，提高 CPU 的利用率。使用时我们也需要注意以下问题：

* sync.Cond.Wait 在调用之前一定要使用获取互斥锁，否则会触发程序崩溃；
* sync.Cond.Signal 唤醒的 Goroutine 都是队列最前面、等待最久的 Goroutine；
* sync.Cond.Broadcast 会按照一定顺序广播通知等待的全部 Goroutine


## timer
* Go 1.9 版本之前，所有的计时器由全局唯一的四叉堆维护: 全局唯一的互斥锁，这会严重影响计时器的性能
* Go 1.10 ~ 1.13，全局使用 64 个四叉堆维护全部的计时器，每个处理器（P）创建的计时器会由对应的四叉堆维护: 能够降低锁的粒度，提高计时器的性能;处理器和线程之间频繁的上下文切换却成为了影响计时器性能的首要因素
* Go 1.14 版本之后，每个处理器单独管理计时器并通过网络轮询器触发

目前计时器都交由处理器的网络轮询器和调度器触发，这种方式能够充分利用本地性、减少上下文的切换开销，也是目前性能最好的实现方式

### 数据结构
```go
//src/time/sleep.go
// Timer代表一次定时，时间到来后仅发生一个事件。
type Timer struct { 
    //管道，上层应用根据此管道接收事件
    C <-chan Time
    
    //runtime定时器，该定时器即系统管理的定时器，对上层应用不可见
    r runtimeTimer
}

//创建一个Timer实质上是把一个定时任务交给专门的协程进行监控，这个任务的载体便是runtimeTimer
//src/time/sleep.go
type runtimeTimer struct {
    // 系统底层存储runtimeTimer的数组地址
    tb uintptr    
    
    // 当前runtimeTimer在tb数组中的下标                      
    i  int                              

    // 当前定时器触发时间
    when   int64   
    
    //定时器周期性触发间隔（对于Timer来说，此值恒为0）；                     
    period int64
    
    //定时器触发时执行的回调函数，回调函数接收两个参数；
    f      func(interface{}, uintptr)
    
    // 定时器触发时执行函数传递的参数一
    arg    interface{}   
    
    // 定时器触发时执行函数传递的参数二(该参数只在网络收发场景下使用)               
    seq    uintptr                      
}
```
### Timer
NewTimer()创建一个新的Timer交给系统协程监控；
Stop()通知系统协程删除指定的Timer;
Reset()通知系统协程删除指定的Timer并再添加一个新的Timer；

### Ticker
NewTicker()创建一个新的Ticker交给系统协程监控；
Stop()通知系统协程删除指定的Ticker;

### 实现原理

## channel
不要通过共享内存的方式进行通信，而是应该通过通信的方式共享内存
通信顺序进程（Communicating sequential processes，CSP）。Goroutine 和 Channel 分别对应 CSP 中的实体和传递信息的媒介，Goroutine 之间会通过 Channel 传递数据
### 先入先出
* 先从 Channel 读取数据的 Goroutine 会先接收到数据；
* 先向 Channel 发送数据的 Goroutine 会得到先发送数据的权利
### 无锁管道
* 同步 Channel — 不需要缓冲区，发送方会直接将数据交给（Handoff）接收方；
* 异步 Channel — 基于环形缓存的传统生产者消费者模型；
* chan struct{} 类型的异步 Channel : struct{} 类型不占用内存空间，不需要实现缓冲区和直接发送（Handoff）的语义
### 数据结构
```
type hchan struct {
    //Channel 中的元素个数
	qcount   uint
	
	//Channel 中的循环队列的长度
	dataqsiz uint
	
	// Channel 的缓冲区数据指针
	buf      unsafe.Pointer
	
	//当前 Channel 能够收发的元素大小
	elemsize uint16
	
	closed   uint32
	
	//当前 Channel 能够收发的元素类型
	elemtype *_type
	
	//Channel 的发送操作处理到的位置
	sendx    uint
	
	//Channel 的接收操作处理到的位置
	recvx    uint
	
	//当前 Channel 由于缓冲区空间不足而阻塞的 读Goroutine 列表
	recvq    waitq
	
    ////当前 Channel 由于缓冲区空间不足而阻塞的 写Goroutine 列表
	sendq    waitq

	lock mutex
}
```
### 初始化
* 如果当前 Channel 中不存在缓冲区，那么就只会为 runtime.hchan 分配一段内存空间；
* 如果当前 Channel 中存储的类型不是指针类型，会为当前的 Channel 和底层的数组分配一块连续的内存空间；
* 在默认情况下会单独为 runtime.hchan 和缓冲区分配内存

### 发送数据
* 如果 Channel 已经关闭，那么向该 Channel 发送数据时会报 “send on closed channel” 错误并中止程序
* 当存在等待的接收者时，通过 runtime.send 直接将数据发送给阻塞的接收者：从接收队列 recvq 中取出最先陷入等待的 Goroutine 并直接向它发送数据
* 当缓冲区存在空余空间时，将发送的数据写入 Channel 的缓冲区；
* 当不存在缓冲区或者缓冲区已满时，等待其他 Goroutine 从 Channel 接收数据

* 如果当前 Channel 的 recvq 上存在已经被阻塞的 Goroutine，那么会直接将数据发送给当前 Goroutine 并将其设置成下一个运行的 Goroutine；
* 如果 Channel 存在缓冲区并且其中还有空闲的容量，我们会直接将数据存储到缓冲区 sendx 所在的位置上；
* 如果不满足上面的两种情况，会创建一个 runtime.sudog 结构并将其加入 Channel 的 sendq 队列中，当前 Goroutine 也会陷入阻塞等待其他的协程从 Channel 接收数据；

发送数据的过程中包含几个会触发 Goroutine 调度的时机：

* 发送数据时发现 Channel 上存在等待接收数据的 Goroutine，立刻设置处理器的 runnext 属性，但是并不会立刻触发调度；
* 发送数据时并没有找到接收方并且缓冲区已经满了，这时会将自己加入 Channel 的 sendq 队列并调用 runtime.goparkunlock 触发 Goroutine 的调度让出处理器的使用权
### 接收数据
* 当我们从一个空 Channel 接收数据时会直接调用 runtime.gopark 让出处理器的使用权
* 如果当前 Channel 已经被关闭并且缓冲区中不存在任何数据，那么会清除 ep 指针中的数据并立刻返回
* 当存在等待的发送者时，通过 runtime.recv 从阻塞的发送者或者缓冲区中获取数据；
* 当缓冲区存在数据时，从 Channel 的缓冲区中接收数据；
* 当缓冲区中不存在数据时，等待其他 Goroutine 向 Channel 发送数据

从 Channel 中接收数据时可能会发生的五种情况

* 如果 Channel 为空，那么会直接调用 runtime.gopark 挂起当前 Goroutine；
* 如果 Channel 已经关闭并且缓冲区没有任何数据，runtime.chanrecv 会直接返回；
* 如果 Channel 的 sendq 队列中存在挂起的 Goroutine，会将 recvx 索引所在的数据拷贝到接收变量所在的内存空间上并将 sendq 队列中 Goroutine 的数据拷贝到缓冲区；
* 如果 Channel 的缓冲区中包含数据，那么直接读取 recvx 索引对应的数据；
* 在默认情况下会挂起当前的 Goroutine，将 runtime.sudog 结构加入 recvq 队列并陷入休眠等待调度器的唤醒；
* 
我们总结一下从 Channel 接收数据时，会触发 Goroutine 调度的两个时机：

* 当 Channel 为空时；
* 当缓冲区中不存在数据并且也不存在数据的发送者时

### 关闭channel
当 Channel 是一个空指针或者已经被关闭时，Go 语言运行时都会直接崩溃并抛出异常

### 语法糖
#### 可变参数
可变参函数是指函数的某个参数可有可无，即这个参数个数可以是0个或多个
声明可变参数函数的方式是在参数类型前加上...前缀

* 可变参数必须在函数参数列表的尾部，即最后一个（如放前面会引起编译时歧义）；
* 可变参数在函数内部是作为切片来解析的；
* 可变参数可以不填，不填时函数内部当成nil切片处理；
* 可变参数必须是相同类型的（如果需要是不同类型的可以定义为interface{}类型）

### 网络轮询器
### 系统监控

